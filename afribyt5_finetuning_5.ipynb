{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20692,
     "status": "ok",
     "timestamp": 1767261867976,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "DlWNwYD5MbFY",
    "outputId": "309dbe43-589c-46d6-fd01-398f9f08d3f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers datasets peft accelerate bitsandbytes evaluate bert-score sacrebleu torch\n",
    "%pip install -q sentencepiece sacremoses nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32682,
     "status": "ok",
     "timestamp": 1767261900660,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "HTf9EUMVMbFY",
    "outputId": "e33d9800-82fc-4bb2-d35f-9f087a74f4e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import Dataset as HFDataset\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2722,
     "status": "ok",
     "timestamp": 1767261903377,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "8gT6u4vZQkCU",
    "outputId": "4e15605b-b3fe-4078-d26c-f6772c81f722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data ready\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK data (required for SARI metric)\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "except LookupError:\n",
    "    nltk.download('punkt_tab', quiet=True)\n",
    "print(\"NLTK data ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lNZm-uDMbFZ"
   },
   "source": [
    "## 1. Load and Prepare Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1767261903399,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "3vD8KzoRMbFZ",
    "outputId": "48a21280-a26f-4110-81a0-7a69e658d966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1700 samples\n",
      "Validation: 200 samples\n",
      "Test: 99 samples\n",
      "\n",
      "Sample entry:\n",
      "{\n",
      "  \"legal_sentence\": \"1596. እንደአግባቡ ማመልከቻውን ያቀረበው ሰው ወይም የከሰረው ሰው ንብረት ጠባቂ ተቆጣጣሪ ዳኛው በሰጠው ውሳኔ ላይ ውሳኔው በተሰጠ በአስር ቀናት ውስጥ ለፍርድ ቤት ይግባኝ ማቅረብ ይችላል ።\",\n",
      "  \"simplified_sentence\": \"ባለቤቱ ወይም የንብረት ጠባቂው ዳኛው በሰጠው ውሳኔ ካልተስማሙ በ10 ቀናት ውስጥ ለፍርድ ቤት ይግባኝ ማለት ይችላሉ።\",\n",
      "  \"simplification_type\": \"structure_reordering\"\n",
      "}\n",
      "\n",
      "Using fixed splits for consistency with Model 3\n",
      "Note: simplification_type will be used during training to condition the model on the type of simplification needed\n"
     ]
    }
   ],
   "source": [
    "# Load pre-split datasets (created using create_fixed_splits.py)\n",
    "# This ensures consistency with Model 3 which uses the same splits\n",
    "# Note: simplification_type will be used during training to condition the model\n",
    "with open('/content/regen_train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open('/content/regen_val.json', 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "with open('/content/regen_test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Train: {len(train_data)} samples\")\n",
    "print(f\"Validation: {len(val_data)} samples\")\n",
    "print(f\"Test: {len(test_data)} samples\")\n",
    "print(f\"\\nSample entry:\")\n",
    "print(json.dumps(train_data[0], ensure_ascii=False, indent=2))\n",
    "print(\"\\nUsing fixed splits for consistency with Model 3\")\n",
    "print(\"Note: simplification_type will be used during training to condition the model on the type of simplification needed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmV74ZeKMbFZ"
   },
   "source": [
    "## 2. Dataset Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1767261909219,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "iUKi4fw-MbFZ",
    "outputId": "950d6fb2-b350-48c9-b3fc-cc1f5d15c7be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1700\n",
      "Validation: 200\n",
      "Test: 99\n",
      "\n",
      "Using fixed splits (no random splitting)\n"
     ]
    }
   ],
   "source": [
    "# Data already loaded from pre-split files in Cell 4\n",
    "# No random splitting needed - using fixed splits for consistency\n",
    "print(f\"Train: {len(train_data)}\")\n",
    "print(f\"Validation: {len(val_data)}\")\n",
    "print(f\"Test: {len(test_data)}\")\n",
    "print(\"\\nUsing fixed splits (no random splitting)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Oey68hJMbFa"
   },
   "source": [
    "## 3. Load Model and Tokenizer\n",
    "\n",
    "**Model**: `rasyosef/Llama-3.2-400M-Amharic-Instruct`  \n",
    "**Sequence Lengths**:\n",
    "- Max input length: 512 tokens\n",
    "- Max output length: 256 tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1767261912144,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "PSVpdNeFMbFa",
    "outputId": "03c304dc-945e-4c75-9257-5449a1cc0131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 32000\n",
      "Max input length: 512 tokens\n",
      "Max output length: 256 tokens\n"
     ]
    }
   ],
   "source": [
    "model_name = \"rasyosef/Llama-3.2-400M-Amharic-Instruct\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set pad_token if it doesn't exist (LLaMA models often don't have one)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Sequence length settings for LLaMA\n",
    "max_input_length = 512  # tokens\n",
    "max_output_length = 256  # tokens (for simplified sentences)\n",
    "\n",
    "print(f\"Tokenizer vocab size: {tokenizer.vocab_size}\")\n",
    "print(f\"Max input length: {max_input_length} tokens\")\n",
    "print(f\"Max output length: {max_output_length} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "88616dc133134deb8b36eaddf9d29dec",
      "3127f999723941eb8c541dd9f52f797d",
      "a13db7f9c36d40669b338589f92467b8",
      "26dd17af41994394b5f1ca02f41e6b31",
      "53212124d8c84024b76b3d20408bbafa",
      "b121fb037a164801affc9aa0d1f729b6",
      "b02ed9f84ced4ef48e913299e6d7bc84",
      "33f7f049fd0e40b4bc8b1f26c11194f7",
      "efdcc3b7653a48efb20a86643b73af7c",
      "c3b7295c5c184cb0b5b3407c884574c2",
      "042f5350670b43a9b90887cefd647e16",
      "3a11f48e671948f288a971cd4d513e54",
      "e8e34dafcdc042739ec6301bc1557575",
      "b66ffce02a724bc49a488658a7fe129d",
      "525beed07ca6468e949705e36909899d",
      "cd7eadf50b4149e4979d32f48c9f093a",
      "1a550ea1af5c441d85f2666010425fcd",
      "ed8530a60c3543d78f03e2392db8949d",
      "b76542c82bff4743ae390d89fded3e2c",
      "642449d2bdd14f698b2fbcf81967ef8f",
      "a666042659ab482a84ec207a4528c952",
      "69cfe696ffcb4c3ebe9ae37624ba7795",
      "325372b44e904caa9ba0e0c9befa0ddf",
      "94cb7b935d594f89b4e1841290ffcac8",
      "1a377ab05ae144a69b98b01e2e55416f",
      "fd84c3fcd3ae43bfa919002326668d42",
      "4efca05f1d3945d281e0c013e1c01672",
      "c5b4222e818846b8854bcd676dc3a8ae",
      "14ecfcc373cc43fe9eaf9fa0de72fe64",
      "2827a1e88af149f6b525040ceb324a4e",
      "d834fde5338049c095703200b550b053",
      "63ea14d885db49efb2427057ea0bf41b",
      "df29dea7e70547b088225d7fdcfabdde"
     ]
    },
    "executionInfo": {
     "elapsed": 29022,
     "status": "ok",
     "timestamp": 1767261944038,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "DuhVKZmXMbFa",
    "outputId": "0458193e-cc30-4061-e2d7-165c14cc1a37"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88616dc133134deb8b36eaddf9d29dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/782 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a11f48e671948f288a971cd4d513e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325372b44e904caa9ba0e0c9befa0ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/144 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: rasyosef/Llama-3.2-400M-Amharic-Instruct\n",
      "Model parameters: 412,531,200\n"
     ]
    }
   ],
   "source": [
    "# Load model with appropriate dtype for memory efficiency\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Ensure model config has pad_token_id set\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLYPAA4sMbFa"
   },
   "source": [
    "## 4. Configure LoRA\n",
    "\n",
    "LoRA is applied to attention layers as a regularization mechanism to reduce overfitting on a small dataset, while still allowing end-to-end adaptation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19257,
     "status": "ok",
     "timestamp": 1767261967016,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "uPgVy-cAMbFb",
    "outputId": "8d4f2423-5cb6-48f5-e0f3-4e5eab4b2de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 9,633,792 || all params: 422,164,992 || trainable%: 2.2820\n",
      "Model already on device\n"
     ]
    }
   ],
   "source": [
    "# LoRA configuration for LLaMA decoder-only model\n",
    "# Increased rank since we have room (400M model vs 530M+ AfriByT5)\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=64,  # Increased from 32 (more capacity for 400M model)\n",
    "    lora_alpha=128,  # Increased proportionally (2x r)\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # LLaMA attention projection layers\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Enable gradient requirements for PEFT models\n",
    "if hasattr(model, 'enable_input_require_grads'):\n",
    "    model.enable_input_require_grads()\n",
    "\n",
    "# Move model to device if not already there\n",
    "if not next(model.parameters()).is_cuda and torch.cuda.is_available():\n",
    "    model = model.to(device)\n",
    "    print(f\"Model moved to {device}\")\n",
    "else:\n",
    "    print(f\"Model already on device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFEYuYuKMbFb"
   },
   "source": [
    "## 5. Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99,
     "referenced_widgets": [
      "01ffcaf3507b4a918fd7e36b8c1472fb",
      "5bd102450035490d96557d569fb21bd2",
      "69c0de24bf50412684809e476e0ec1ae",
      "b4d65674747242cbaf95bc24698d2abf",
      "783e72bb26c34e0591cf5917554768bd",
      "82c604c09e23437a8984b54355d236b5",
      "7cd3dc1bf55740a9b85b86bfec9f6e8e",
      "601e597d1c6440c582690dec937634ac",
      "c238a47b77da40fa895f98bfca3d3a1e",
      "d994bb9de1c84959822739733a801e5b",
      "5cd936be671a4d3ca6532966a571f4c0",
      "caae7ad40ef549c8a7d452a22e4e535a",
      "1a283683ada94ad49c898e944b4f54e9",
      "b3cacb2c4efb41fb827f781326ac941d",
      "905de677c9a149f89853aa61f97a25d9",
      "836e8c3d29174af3b8b2d6ad14a6b103",
      "e188176142994c629c61f5f3d69ff623",
      "9b4d8ef44dfb41a799f61f1b5772f567",
      "a75bc159437a44338c36361e040e20a4",
      "bd2bf9edbe8b40bb94c65bd2160b047e",
      "4c636329a5fc4291b787e9f44befd1ea",
      "6e3f0e6c36e347529b3de201b0ed71e6"
     ]
    },
    "executionInfo": {
     "elapsed": 3439,
     "status": "ok",
     "timestamp": 1767262122518,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "7Vyulm4XMbFb",
    "outputId": "20e01d8b-7a13-46ce-ba6a-1e6c1bd0d930"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ffcaf3507b4a918fd7e36b8c1472fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caae7ad40ef549c8a7d452a22e4e535a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets tokenized and ready\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"Tokenize and prepare inputs for causal LM with simplification instruction and type\"\"\"\n",
    "    inputs = examples[\"legal_sentence\"] if isinstance(examples[\"legal_sentence\"], list) else [examples[\"legal_sentence\"]]\n",
    "    targets = examples[\"simplified_sentence\"] if isinstance(examples[\"simplified_sentence\"], list) else [examples[\"simplified_sentence\"]]\n",
    "    sim_types = examples.get(\"simplification_type\", [\"unknown\"] * len(inputs))\n",
    "    if not isinstance(sim_types, list):\n",
    "        sim_types = [sim_types]\n",
    "\n",
    "    base_instruction = \"የሕግ ቃላትን ለግለሰቦች ለመረዳት ቀላል አማርኛ ውስጥ አቅርብ: \"\n",
    "    type_map = {\n",
    "        \"vocabulary_simplification\": \"[የቃላት ማቃለል]\",\n",
    "        \"sentence_splitting\": \"[የዓረፍተ ነገር መከፋፈል]\",\n",
    "        \"deletion\": \"[መሻር]\",\n",
    "        \"unknown\": \"[አጠቃላይ]\"\n",
    "    }\n",
    "\n",
    "    # Format: instruction + type_label + legal_sentence + simplified_sentence\n",
    "    formatted_texts = []\n",
    "    input_lengths = []\n",
    "\n",
    "    for inp, target, sim_type in zip(inputs, targets, sim_types):\n",
    "        type_label = type_map.get(sim_type, f\"[{sim_type}]\")\n",
    "        input_part = base_instruction + type_label + \" \" + inp\n",
    "        full_text = input_part + \" \" + target\n",
    "        formatted_texts.append(full_text)\n",
    "\n",
    "        # Tokenize input part to get its length\n",
    "        input_tokens = tokenizer(input_part, add_special_tokens=True, return_tensors=None)[\"input_ids\"]\n",
    "        input_lengths.append(len(input_tokens))\n",
    "\n",
    "    # Tokenize full sequences with padding\n",
    "    max_seq_length = max_input_length + max_output_length\n",
    "    tokenized = tokenizer(\n",
    "        formatted_texts,\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",  # CRITICAL: pad to same length\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    # Create labels: -100 for input, actual tokens for output\n",
    "    labels = []\n",
    "    for i, input_len in enumerate(input_lengths):\n",
    "        full_tokens = tokenized[\"input_ids\"][i]\n",
    "        full_len = len(full_tokens)\n",
    "\n",
    "        label = [-100] * full_len\n",
    "        # Set labels for output portion (after input)\n",
    "        for j in range(input_len, min(full_len, len(full_tokens))):\n",
    "            label[j] = full_tokens[j]  # Use actual token id for output\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "# Convert to HuggingFace datasets\n",
    "train_dataset = HFDataset.from_list(train_data)\n",
    "val_dataset = HFDataset.from_list(val_data)\n",
    "test_dataset = HFDataset.from_list(test_data)\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "val_dataset = val_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=val_dataset.column_names\n",
    ")\n",
    "\n",
    "print(\"Datasets tokenized and ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvR045qLMbFb"
   },
   "source": [
    "## 6. Setup Metrics\n",
    "\n",
    "**Primary Metric**: SARI (System output Against References and Inputs)  \n",
    "**Secondary Metric**: BERTScore (multilingual)\n",
    "\n",
    "Automatic metrics are complemented with qualitative evaluation on held-out legal sentences to verify preservation of legal meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 3609,
     "status": "ok",
     "timestamp": 1767262128493,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "lUbjggUnMbFb"
   },
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "sari_metric = load(\"sari\")\n",
    "bertscore_metric = load(\"bertscore\")\n",
    "bleu_metric = load(\"sacrebleu\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute SARI and BERTScore\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Handle nested arrays and convert to numpy if needed\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "    if isinstance(labels, tuple):\n",
    "        labels = labels[0]\n",
    "\n",
    "    # Convert to numpy arrays if they're not already\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # If predictions are logits (shape has extra dimension), take argmax\n",
    "    if len(predictions.shape) > 1 and predictions.shape[-1] > 1:\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    # Replace -100 in labels with pad_token_id for decoding (data collator uses -100 for ignored tokens)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    # Decode predictions and labels\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Compute BERTScore\n",
    "    bertscore_result = bertscore_metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels,\n",
    "        lang=\"am\",  # Amharic\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"bertscore_f1\": np.mean(bertscore_result[\"f1\"])\n",
    "    }\n",
    "\n",
    "# Note: SARI requires source sentences, which we'll compute separately during evaluation\n",
    "\n",
    "# Note: SARI requires source sentences, which we'll compute separately during evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFxYX-PCMbFb"
   },
   "source": [
    "## 7. Training Configuration\n",
    "\n",
    "**Key Settings**:\n",
    "- Label smoothing: 0.1\n",
    "- Early stopping: patience 2 epochs, monitor validation SARI\n",
    "- Learning rate: 2e-4\n",
    "- Batch size: 8\n",
    "- Gradient accumulation: 8 (effective batch size: 64)\n",
    "- Epochs: 6 (increased from 4)\n",
    "- LR scheduler: Cosine with warmup_ratio=0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1767262131253,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "5z8QwDCpMbFb",
    "outputId": "eed80be9-52a1-479e-93dd-578a6f9808e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training arguments configured\n"
     ]
    }
   ],
   "source": [
    "# Data collator for causal language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # We're doing causal LM, not masked LM\n",
    "    pad_to_multiple_of=8  # For efficiency\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama-400m-legal-simplification\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=6,  # Increased from 4 for better learning\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=8,  # Increased from 4 (effective batch size: 64)\n",
    "    learning_rate=2e-4,  # Keep current (don't lower unless instability appears)\n",
    "    lr_scheduler_type=\"cosine\",  # Added: cosine decay for better convergence\n",
    "    warmup_ratio=0.1,  # Added: warmup ratio (replaces warmup_steps)\n",
    "    logging_steps=50,\n",
    "    eval_steps=200,  # More frequent evaluation (from 300)\n",
    "    save_steps=200,  # More frequent saving (from 300)\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_sari\",\n",
    "    greater_is_better=True,\n",
    "    label_smoothing_factor=0.1,\n",
    "    fp16=True,  # Changed from bf16 to fp16 as requested\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "print(\"Training arguments configured\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIhHjMExMbFb"
   },
   "source": [
    "## 8. Custom Trainer with SARI-based Early Stopping\n",
    "\n",
    "Early stopping patience: 2 epochs, monitoring validation SARI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1767262133961,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "Lr5HEzK6MbFb",
    "outputId": "f89c8828-816a-4ab3-9032-af7e17884de3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized with SARI-based early stopping\n"
     ]
    }
   ],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    \"\"\"Custom trainer that computes SARI for early stopping\"\"\"\n",
    "\n",
    "    def __init__(self, *args, source_sentences=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.source_sentences = source_sentences\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        \"\"\"Override evaluate to include SARI\"\"\"\n",
    "        eval_dataset = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = self.predict(eval_dataset)\n",
    "        pred_texts = tokenizer.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
    "        label_texts = tokenizer.batch_decode(predictions.label_ids, skip_special_tokens=True)\n",
    "\n",
    "        # Compute BERTScore\n",
    "        bertscore_result = bertscore_metric.compute(\n",
    "            predictions=pred_texts,\n",
    "            references=label_texts,\n",
    "            lang=\"am\",\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Compute SARI if we have source sentences\n",
    "        sari_scores = []\n",
    "        if self.source_sentences is not None:\n",
    "            for i, (source, pred, ref) in enumerate(zip(self.source_sentences, pred_texts, label_texts)):\n",
    "                try:\n",
    "                    sari = sari_metric.compute(\n",
    "                        sources=[source],\n",
    "                        predictions=[pred],\n",
    "                        references=[[ref]]\n",
    "                    )\n",
    "                    sari_scores.append(sari[\"sari\"])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        metrics = {\n",
    "            f\"{metric_key_prefix}_bertscore_f1\": np.mean(bertscore_result[\"f1\"]),\n",
    "        }\n",
    "\n",
    "        # Always compute SARI if source sentences are available\n",
    "        if sari_scores:\n",
    "            metrics[f\"{metric_key_prefix}_sari\"] = np.mean(sari_scores)\n",
    "        else:\n",
    "            # If SARI couldn't be computed, set a default value to avoid errors\n",
    "            metrics[f\"{metric_key_prefix}_sari\"] = 0.0\n",
    "\n",
    "        self.log(metrics)\n",
    "        return metrics\n",
    "\n",
    "# Custom callback to clear GPU cache during evaluation\n",
    "class MemoryClearingCallback(EarlyStoppingCallback):\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        \"\"\"Clear GPU cache after each evaluation to prevent OOM\"\"\"\n",
    "        import torch\n",
    "        torch.cuda.empty_cache()\n",
    "        return super().on_evaluate(args, state, control, **kwargs)\n",
    "\n",
    "# Prepare source sentences for validation set (for SARI computation)\n",
    "val_source_sentences = [item[\"legal_sentence\"] for item in val_data]\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    source_sentences=val_source_sentences,\n",
    "    callbacks=[MemoryClearingCallback(early_stopping_patience=2)],\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized with SARI-based early stopping\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUnYNf0hMbFb"
   },
   "source": [
    "## 9. Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 1405984,
     "status": "ok",
     "timestamp": 1767263987930,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "COPIVBqKMbFc",
    "outputId": "16390b01-91bb-4829-df64-9d6b7f48a3dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 39/162 07:04 < 23:30, 0.09 it/s, Epoch 1.41/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [162/162 30:36, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./llama-400m-legal-simplification/tokenizer_config.json',\n",
       " './llama-400m-legal-simplification/special_tokens_map.json',\n",
       " './llama-400m-legal-simplification/chat_template.jinja',\n",
       " './llama-400m-legal-simplification/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# Enable gradient checkpointing for memory efficiency\n",
    "if hasattr(model, 'gradient_checkpointing_enable'):\n",
    "    model.gradient_checkpointing_enable()\n",
    "if hasattr(model.config, 'use_cache'):\n",
    "    model.config.use_cache = False\n",
    "\n",
    "# Train\n",
    "print(\"Starting training...\")\n",
    "train_result = trainer.train()\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Save final model\n",
    "trainer.save_model(\"./llama-400m-legal-simplification\")\n",
    "tokenizer.save_pretrained(\"./llama-400m-legal-simplification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training Visualizations\n",
    "\n",
    "Visualize training progress, validation metrics, and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Extract training history from trainer state\n",
    "train_history = trainer.state.log_history\n",
    "\n",
    "# Separate training and evaluation logs\n",
    "train_logs = [log for log in train_history if 'loss' in log and 'eval_loss' not in log]\n",
    "eval_logs = [log for log in train_history if 'eval_loss' in log]\n",
    "\n",
    "# Extract data\n",
    "train_steps = [log['step'] for log in train_logs]\n",
    "train_losses = [log['loss'] for log in train_logs]\n",
    "\n",
    "eval_steps = [log['step'] for log in eval_logs]\n",
    "eval_losses = [log.get('eval_loss', 0) for log in eval_logs]\n",
    "eval_sari = [log.get('eval_sari', 0) for log in eval_logs]\n",
    "eval_bertscore = [log.get('eval_bertscore_f1', 0) for log in eval_logs]\n",
    "\n",
    "# Create comprehensive figure\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Plot 1: Training Loss (top left, spans 2 columns)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.plot(train_steps, train_losses, 'b-', linewidth=2.5, label='Training Loss', alpha=0.8)\n",
    "ax1.set_xlabel('Training Steps', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('Loss', fontsize=13, fontweight='bold')\n",
    "ax1.set_title('Training Loss Over Time', fontsize=15, fontweight='bold', pad=15)\n",
    "ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "ax1.legend(fontsize=12, loc='best')\n",
    "ax1.set_facecolor('#f8f9fa')\n",
    "\n",
    "# Plot 2: Validation Loss\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "if eval_losses and any(l > 0 for l in eval_losses):\n",
    "    ax2.plot(eval_steps, eval_losses, 'r-', linewidth=2.5, marker='o', markersize=5, label='Validation Loss', alpha=0.8)\n",
    "    ax2.set_xlabel('Training Steps', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Validation Loss', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.set_facecolor('#f8f9fa')\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'No validation data', ha='center', va='center', fontsize=12)\n",
    "    ax2.set_title('Validation Loss', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 3: SARI Score\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "if eval_sari and any(s > 0 for s in eval_sari):\n",
    "    ax3.plot(eval_steps, eval_sari, 'g-', linewidth=2.5, marker='s', markersize=5, label='SARI', alpha=0.8)\n",
    "    ax3.set_xlabel('Training Steps', fontsize=12, fontweight='bold')\n",
    "    ax3.set_ylabel('SARI Score', fontsize=12, fontweight='bold')\n",
    "    ax3.set_title('SARI Score (Simplification Quality)', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax3.legend(fontsize=11)\n",
    "    ax3.set_ylim(bottom=0)\n",
    "    ax3.set_facecolor('#f8f9fa')\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'No SARI data', ha='center', va='center', fontsize=12)\n",
    "    ax3.set_title('SARI Score', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 4: BERTScore F1\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "if eval_bertscore and any(b > 0 for b in eval_bertscore):\n",
    "    ax4.plot(eval_steps, eval_bertscore, 'm-', linewidth=2.5, marker='^', markersize=5, label='BERTScore F1', alpha=0.8)\n",
    "    ax4.set_xlabel('Training Steps', fontsize=12, fontweight='bold')\n",
    "    ax4.set_ylabel('BERTScore F1', fontsize=12, fontweight='bold')\n",
    "    ax4.set_title('BERTScore F1 (Semantic Similarity)', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax4.legend(fontsize=11)\n",
    "    ax4.set_ylim(bottom=0, top=1)\n",
    "    ax4.set_facecolor('#f8f9fa')\n",
    "else:\n",
    "    ax4.text(0.5, 0.5, 'No BERTScore data', ha='center', va='center', fontsize=12)\n",
    "    ax4.set_title('BERTScore F1', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 5: Combined Loss Plot (Training vs Validation)\n",
    "ax5 = fig.add_subplot(gs[2, 1])\n",
    "if eval_losses and any(l > 0 for l in eval_losses):\n",
    "    ax5.plot(train_steps, train_losses, 'b-', linewidth=2, label='Training Loss', alpha=0.7)\n",
    "    ax5.plot(eval_steps, eval_losses, 'r-', linewidth=2, marker='o', markersize=4, label='Validation Loss', alpha=0.7)\n",
    "    ax5.set_xlabel('Training Steps', fontsize=12, fontweight='bold')\n",
    "    ax5.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "    ax5.set_title('Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax5.legend(fontsize=11)\n",
    "    ax5.set_facecolor('#f8f9fa')\n",
    "else:\n",
    "    ax5.plot(train_steps, train_losses, 'b-', linewidth=2, label='Training Loss', alpha=0.7)\n",
    "    ax5.set_xlabel('Training Steps', fontsize=12, fontweight='bold')\n",
    "    ax5.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "    ax5.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax5.legend(fontsize=11)\n",
    "    ax5.set_facecolor('#f8f9fa')\n",
    "\n",
    "# Add overall title\n",
    "fig.suptitle('Training Progress: AfriByT5 Legal Simplification', fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "# Save high-resolution plot\n",
    "plot_path = \"./afribyt5-legal-simplification_training_plots.png\"\n",
    "fig.savefig(plot_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"\\nTraining plots saved to: {plot_path}\")\n",
    "\n",
    "# Print detailed summary statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING SUMMARY: AfriByT5 Legal Simplification\")\n",
    "print(\"=\"*70)\n",
    "if train_losses:\n",
    "    print(f\"\\nTraining Loss:\")\n",
    "    print(f\"  Initial: {train_losses[0]:.4f}\")\n",
    "    print(f\"  Final: {train_losses[-1]:.4f}\")\n",
    "    print(f\"  Best: {min(train_losses):.4f} (at step {train_steps[train_losses.index(min(train_losses))]})\")\n",
    "    print(f\"  Improvement: {((train_losses[0] - min(train_losses)) / train_losses[0] * 100):.2f}%\")\n",
    "if eval_losses and any(l > 0 for l in eval_losses):\n",
    "    valid_losses = [l for l in eval_losses if l > 0]\n",
    "    valid_steps = [eval_steps[i] for i, l in enumerate(eval_losses) if l > 0]\n",
    "    print(f\"\\nValidation Loss:\")\n",
    "    print(f\"  Initial: {valid_losses[0]:.4f}\")\n",
    "    print(f\"  Final: {valid_losses[-1]:.4f}\")\n",
    "    print(f\"  Best: {min(valid_losses):.4f} (at step {valid_steps[valid_losses.index(min(valid_losses))]})\")\n",
    "    print(f\"  Improvement: {((valid_losses[0] - min(valid_losses)) / valid_losses[0] * 100):.2f}%\")\n",
    "if eval_sari and any(s > 0 for s in eval_sari):\n",
    "    valid_sari = [s for s in eval_sari if s > 0]\n",
    "    valid_steps = [eval_steps[i] for i, s in enumerate(eval_sari) if s > 0]\n",
    "    print(f\"\\nSARI Score:\")\n",
    "    print(f\"  Initial: {valid_sari[0]:.4f}\")\n",
    "    print(f\"  Final: {valid_sari[-1]:.4f}\")\n",
    "    print(f\"  Best: {max(valid_sari):.4f} (at step {valid_steps[valid_sari.index(max(valid_sari))]})\")\n",
    "    print(f\"  Improvement: {((max(valid_sari) - valid_sari[0]) / valid_sari[0] * 100):.2f}%\")\n",
    "if eval_bertscore and any(b > 0 for b in eval_bertscore):\n",
    "    valid_bertscore = [b for b in eval_bertscore if b > 0]\n",
    "    valid_steps = [eval_steps[i] for i, b in enumerate(eval_bertscore) if b > 0]\n",
    "    print(f\"\\nBERTScore F1:\")\n",
    "    print(f\"  Initial: {valid_bertscore[0]:.4f}\")\n",
    "    print(f\"  Final: {valid_bertscore[-1]:.4f}\")\n",
    "    print(f\"  Best: {max(valid_bertscore):.4f} (at step {valid_steps[valid_bertscore.index(max(valid_bertscore))]})\")\n",
    "    print(f\"  Improvement: {((max(valid_bertscore) - valid_bertscore[0]) / valid_bertscore[0] * 100):.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27845,
     "status": "ok",
     "timestamp": 1767264016985,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "Yj8qCs36Vm73",
    "outputId": "33fcaa39-129e-438e-b2d3-49acc42f5ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10465,
     "status": "ok",
     "timestamp": 1767264027409,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "gffzjLGatFSc",
    "outputId": "0681859a-0731-4f23-dc53-b84fd869d32d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: llama-400m-legal-simplification/ (stored 0%)\n",
      "  adding: llama-400m-legal-simplification/adapter_model.safetensors (deflated 8%)\n",
      "  adding: llama-400m-legal-simplification/special_tokens_map.json (deflated 72%)\n",
      "  adding: llama-400m-legal-simplification/adapter_config.json (deflated 57%)\n",
      "  adding: llama-400m-legal-simplification/tokenizer_config.json (deflated 96%)\n",
      "  adding: llama-400m-legal-simplification/training_args.bin (deflated 53%)\n",
      "  adding: llama-400m-legal-simplification/chat_template.jinja (deflated 37%)\n",
      "  adding: llama-400m-legal-simplification/README.md (deflated 65%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/ (stored 0%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/adapter_model.safetensors (deflated 8%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/special_tokens_map.json (deflated 72%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/adapter_config.json (deflated 57%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/tokenizer_config.json (deflated 96%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/training_args.bin (deflated 53%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/scheduler.pt (deflated 62%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/optimizer.pt (deflated 9%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/chat_template.jinja (deflated 37%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/README.md (deflated 65%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/trainer_state.json (deflated 60%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/scaler.pt (deflated 64%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/rng_state.pth (deflated 26%)\n",
      "  adding: llama-400m-legal-simplification/checkpoint-162/tokenizer.json (deflated 85%)\n",
      "  adding: llama-400m-legal-simplification/tokenizer.json (deflated 85%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r llama-400m-legal-simplification5.zip llama-400m-legal-simplification\n",
    "!cp llama-400m-legal-simplification5.zip /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "error",
     "timestamp": 1767264031172,
     "user": {
      "displayName": "abiy wondimu",
      "userId": "15375001768069333304"
     },
     "user_tz": -180
    },
    "id": "v2B5cqW4tL8X",
    "outputId": "c92ed26f-6bd5-4d90-c454-5276c39eb1fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating Clean Test Set ===\n",
      "Sentences in train: 1667\n",
      "Sentences in val: 200\n",
      "Total unique sentences seen during training: 1857\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1798282746.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Step 2: From the ORIGINAL data list, find items NOT in train or val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0munseen_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Go through ALL original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"legal_sentence\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_seen_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0munseen_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a truly unseen test set\n",
    "print(\"=== Creating Clean Test Set ===\")\n",
    "\n",
    "# Step 1: Get all sentences that were used in training/validation\n",
    "train_sentences = set([item[\"legal_sentence\"] for item in train_data])\n",
    "val_sentences = set([item[\"legal_sentence\"] for item in val_data])\n",
    "all_seen_sentences = train_sentences.union(val_sentences)\n",
    "\n",
    "print(f\"Sentences in train: {len(train_sentences)}\")\n",
    "print(f\"Sentences in val: {len(val_sentences)}\")\n",
    "print(f\"Total unique sentences seen during training: {len(all_seen_sentences)}\")\n",
    "\n",
    "# Step 2: From the ORIGINAL data list, find items NOT in train or val\n",
    "unseen_data = []\n",
    "for item in data:  # Go through ALL original data\n",
    "    if item[\"legal_sentence\"] not in all_seen_sentences:\n",
    "        unseen_data.append(item)\n",
    "\n",
    "print(f\"\\nOriginal data size: {len(data)}\")\n",
    "print(f\"Unseen data available: {len(unseen_data)}\")\n",
    "\n",
    "# Step 3: Take first 100 (or available) from truly unseen data\n",
    "clean_test_size = min(100, len(unseen_data))\n",
    "clean_test_data = unseen_data[:clean_test_size]\n",
    "\n",
    "print(f\"Created clean test set with {len(clean_test_data)} samples\")\n",
    "print(f\"   (These samples were NEVER in train or val)\")\n",
    "\n",
    "# Step 4: Verify no overlap\n",
    "clean_test_sentences = set([item[\"legal_sentence\"] for item in clean_test_data])\n",
    "overlap = all_seen_sentences.intersection(clean_test_sentences)\n",
    "\n",
    "if overlap:\n",
    "    print(f\"ERROR: Still found {len(overlap)} overlapping sentences!\")\n",
    "    print(\"This shouldn't happen. Check for duplicate entries in original data.\")\n",
    "else:\n",
    "    print(\"Verified: Clean test set has ZERO overlap with train or val!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRHf4JGHMbFc"
   },
   "source": [
    "## 10. Evaluation on Test Set\n",
    "\n",
    "Evaluate on the held-out test set (100 samples) that was kept unseen during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYn9xG1jMbFc"
   },
   "outputs": [],
   "source": [
    "# Prepare CLEAN test dataset (truly unseen)\n",
    "clean_test_source_sentences = [item[\"legal_sentence\"] for item in clean_test_data]\n",
    "clean_test_target_sentences = [item[\"simplified_sentence\"] for item in clean_test_data]\n",
    "# Keep simplification_type for analysis\n",
    "clean_test_simplification_types = [item.get(\"simplification_type\", \"unknown\") for item in clean_test_data]\n",
    "\n",
    "# Add instruction prompt with simplification_type for inference (same as training)\n",
    "base_instruction = \"የሕግ ቃላትን ለግለሰቦች ለመረዳት ቀላል አማርኛ ውስጥ አቅርብ: \"\n",
    "type_map = {\n",
    "    \"vocabulary_simplification\": \"[የቃላት ማቃለል]\",\n",
    "    \"sentence_splitting\": \"[የዓረፍተ ነገር መከፋፈል]\",\n",
    "    \"deletion\": \"[መሻር]\",\n",
    "    \"unknown\": \"[አጠቃላይ]\"\n",
    "}\n",
    "prompted_test_sentences = [\n",
    "    base_instruction + type_map.get(sim_type, f\"[{sim_type}]\") + \" \" + sent\n",
    "    for sent, sim_type in zip(clean_test_source_sentences, clean_test_simplification_types)\n",
    "]\n",
    "\n",
    "# Tokenize inputs for inference\n",
    "clean_test_inputs = tokenizer(\n",
    "    prompted_test_sentences,\n",
    "    max_length=max_input_length,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Generate predictions directly (bypassing trainer.predict)\n",
    "print(\"Evaluating on CLEAN test set (truly unseen)...\")\n",
    "clean_test_pred_texts = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx in range(0, len(clean_test_source_sentences), 8):  # Process in batches of 8\n",
    "        batch_input_ids = clean_test_inputs[\"input_ids\"][batch_idx:batch_idx+8]\n",
    "        batch_attention_mask = clean_test_inputs[\"attention_mask\"][batch_idx:batch_idx+8]\n",
    "\n",
    "        # Generate with improved parameters for decoder-only model\n",
    "        outputs = model.generate(\n",
    "            input_ids=batch_input_ids,\n",
    "            attention_mask=batch_attention_mask,\n",
    "            max_new_tokens=256,  # Reduced for simplified sentences\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.3,  # Penalize repetition\n",
    "            no_repeat_ngram_size=3,  # Prevent 3-gram repetition\n",
    "            length_penalty=0.7,  # Encourage shorter outputs\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "        # Decode batch - need to extract only the generated part (after input)\n",
    "        batch_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        # For causal LM, outputs include the input, so we need to extract only the generated part\n",
    "        # The input length varies, so we'll decode and then remove the input portion\n",
    "        for j, (pred, orig_input) in enumerate(zip(batch_preds, prompted_test_sentences[batch_idx:batch_idx+8])):\n",
    "            # Remove the input portion from the prediction\n",
    "            if pred.startswith(orig_input):\n",
    "                pred = pred[len(orig_input):].strip()\n",
    "            clean_test_pred_texts.append(pred)\n",
    "\n",
    "        if (batch_idx // 8 + 1) % 10 == 0:\n",
    "            print(f\"Processed {min(batch_idx+8, len(clean_test_source_sentences))}/{len(clean_test_source_sentences)} samples...\")\n",
    "\n",
    "print(f\"Generated {len(clean_test_pred_texts)} predictions\")\n",
    "\n",
    "# Use original target sentences for metrics\n",
    "clean_test_label_texts = clean_test_target_sentences\n",
    "\n",
    "# Compute metrics\n",
    "print(\"\\n=== CLEAN Test Set Results (Truly Unseen) ===\")\n",
    "\n",
    "# BERTScore\n",
    "bertscore_clean = bertscore_metric.compute(\n",
    "    predictions=clean_test_pred_texts,\n",
    "    references=clean_test_label_texts,\n",
    "    lang=\"am\",\n",
    "    device=device\n",
    ")\n",
    "print(f\"BERTScore F1: {np.mean(bertscore_clean['f1']):.4f}\")\n",
    "\n",
    "# SARI\n",
    "sari_scores_clean = []\n",
    "for source, pred, ref in zip(clean_test_source_sentences, clean_test_pred_texts, clean_test_label_texts):\n",
    "    try:\n",
    "        sari = sari_metric.compute(\n",
    "            sources=[source],\n",
    "            predictions=[pred],\n",
    "            references=[[ref]]\n",
    "        )\n",
    "        sari_scores_clean.append(sari[\"sari\"])\n",
    "    except Exception as e:\n",
    "        print(f\"SARI computation error: {e}\")\n",
    "        pass\n",
    "\n",
    "if sari_scores_clean:\n",
    "    print(f\"SARI: {np.mean(sari_scores_clean):.4f}\")\n",
    "\n",
    "# BLEU Score\n",
    "bleu_result = bleu_metric.compute(\n",
    "    predictions=clean_test_pred_texts,\n",
    "    references=[[ref] for ref in clean_test_label_texts]\n",
    ")\n",
    "print(f\"BLEU: {bleu_result['score']:.4f}\")\n",
    "\n",
    "# Exact Match\n",
    "exact_matches = sum(1 for pred, ref in zip(clean_test_pred_texts, clean_test_label_texts) if pred == ref)\n",
    "exact_match_rate = exact_matches / len(clean_test_pred_texts)\n",
    "print(f\"Exact Match: {exact_match_rate:.4f} ({exact_matches}/{len(clean_test_pred_texts)})\")\n",
    "\n",
    "# Length Statistics\n",
    "source_lengths = [len(s) for s in clean_test_source_sentences]\n",
    "pred_lengths = [len(p) for p in clean_test_pred_texts]\n",
    "ref_lengths = [len(r) for r in clean_test_label_texts]\n",
    "\n",
    "print(f\"\\n=== Length Statistics ===\")\n",
    "print(f\"Source (original):\")\n",
    "print(f\"  Mean: {np.mean(source_lengths):.1f} chars, Median: {np.median(source_lengths):.1f} chars\")\n",
    "print(f\"  Min: {np.min(source_lengths)} chars, Max: {np.max(source_lengths)} chars\")\n",
    "print(f\"\\nPrediction (simplified):\")\n",
    "print(f\"  Mean: {np.mean(pred_lengths):.1f} chars, Median: {np.median(pred_lengths):.1f} chars\")\n",
    "print(f\"  Min: {np.min(pred_lengths)} chars, Max: {np.max(pred_lengths)} chars\")\n",
    "print(f\"\\nReference (target):\")\n",
    "print(f\"  Mean: {np.mean(ref_lengths):.1f} chars, Median: {np.median(ref_lengths):.1f} chars\")\n",
    "print(f\"  Min: {np.min(ref_lengths)} chars, Max: {np.max(ref_lengths)} chars\")\n",
    "\n",
    "# Length ratio (prediction vs source)\n",
    "length_ratios = [p/s if s > 0 else 0 for p, s in zip(pred_lengths, source_lengths)]\n",
    "print(f\"\\nLength Ratio (Prediction/Source):\")\n",
    "print(f\"  Mean: {np.mean(length_ratios):.3f}, Median: {np.median(length_ratios):.3f}\")\n",
    "print(f\"  (Values < 1.0 indicate shortening)\")\n",
    "\n",
    "print(f\"\\nEvaluated {len(clean_test_pred_texts)} CLEAN test samples (truly unseen)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2EfKYIozHfO"
   },
   "outputs": [],
   "source": [
    "# Qualitative Analysis - Check if model is actually simplifying\n",
    "print(\"=== Qualitative Analysis: Is the model really simplifying? ===\\n\")\n",
    "\n",
    "num_samples = 10\n",
    "for i in range(min(num_samples, len(clean_test_source_sentences))):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Original Legal ({len(clean_test_source_sentences[i])} chars):\")\n",
    "    print(f\"  {clean_test_source_sentences[i]}\")\n",
    "    print(f\"\\nReference Simplified ({len(clean_test_target_sentences[i])} chars):\")\n",
    "    print(f\"  {clean_test_target_sentences[i]}\")\n",
    "    print(f\"\\nModel Prediction ({len(clean_test_pred_texts[i])} chars):\")\n",
    "    print(f\"  {clean_test_pred_texts[i]}\")\n",
    "\n",
    "    # Check similarity\n",
    "    if clean_test_pred_texts[i] == clean_test_target_sentences[i]:\n",
    "        print(\"EXACT MATCH - Model might be memorizing!\")\n",
    "    elif clean_test_pred_texts[i] == clean_test_source_sentences[i]:\n",
    "        print(\"NO CHANGE - Model not simplifying!\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKuPRgzcW_kt"
   },
   "outputs": [],
   "source": [
    "# Analyze performance by simplification_type\n",
    "print(\"=== Performance Analysis by Simplification Type ===\\n\")\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Group predictions by simplification_type\n",
    "type_metrics = defaultdict(lambda: {\"sari\": [], \"bertscore\": [], \"count\": 0, \"truncation\": 0, \"repetition\": 0})\n",
    "\n",
    "for i, (source, pred, ref, sim_type) in enumerate(zip(\n",
    "    clean_test_source_sentences,\n",
    "    clean_test_pred_texts,\n",
    "    clean_test_label_texts,\n",
    "    clean_test_simplification_types\n",
    ")):\n",
    "    sim_type = sim_type if sim_type else \"unknown\"\n",
    "    type_metrics[sim_type][\"count\"] += 1\n",
    "\n",
    "    # Compute SARI for this sample\n",
    "    try:\n",
    "        sari = sari_metric.compute(\n",
    "            sources=[source],\n",
    "            predictions=[pred],\n",
    "            references=[[ref]]\n",
    "        )\n",
    "        type_metrics[sim_type][\"sari\"].append(sari[\"sari\"])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Compute BERTScore for this sample\n",
    "    try:\n",
    "        bert = bertscore_metric.compute(\n",
    "            predictions=[pred],\n",
    "            references=[ref],\n",
    "            lang=\"am\",\n",
    "            device=device\n",
    "        )\n",
    "        type_metrics[sim_type][\"bertscore\"].append(np.mean(bert[\"f1\"]))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Check truncation\n",
    "    if pred and pred[-1] not in ['።', '፤', '፥', '፦', '.', '!', '?']:\n",
    "        type_metrics[sim_type][\"truncation\"] += 1\n",
    "\n",
    "    # Check repetition\n",
    "    words = pred.split()\n",
    "    if len(words) > 3:\n",
    "        for j in range(len(words) - 2):\n",
    "            phrase = \" \".join(words[j:j+3])\n",
    "            if pred.count(phrase) > 1:\n",
    "                type_metrics[sim_type][\"repetition\"] += 1\n",
    "                break\n",
    "\n",
    "# Print results by type\n",
    "print(\"Performance breakdown by simplification type:\\n\")\n",
    "for sim_type in sorted(type_metrics.keys()):\n",
    "    metrics = type_metrics[sim_type]\n",
    "    count = metrics[\"count\"]\n",
    "\n",
    "    print(f\"--- {sim_type.upper()} ({count} samples) ---\")\n",
    "    if metrics[\"sari\"]:\n",
    "        print(f\"  Mean SARI: {np.mean(metrics['sari']):.4f}\")\n",
    "    if metrics[\"bertscore\"]:\n",
    "        print(f\"  Mean BERTScore F1: {np.mean(metrics['bertscore']):.4f}\")\n",
    "    print(f\"  Truncation: {metrics['truncation']}/{count} ({100*metrics['truncation']/count:.1f}%)\")\n",
    "    print(f\"  Repetition: {metrics['repetition']}/{count} ({100*metrics['repetition']/count:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nTotal types analyzed: {len(type_metrics)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WM-Jup9CzgBI"
   },
   "outputs": [],
   "source": [
    "# Check for repetition and truncation issues\n",
    "print(\"=== Model Quality Issues ===\")\n",
    "\n",
    "repetition_count = 0\n",
    "truncation_count = 0\n",
    "no_simplification = 0\n",
    "\n",
    "for i, (orig, pred, ref) in enumerate(zip(clean_test_source_sentences, clean_test_pred_texts, clean_test_target_sentences)):\n",
    "    # Check for repetition (same phrase appears 2+ times)\n",
    "    words = pred.split()\n",
    "    if len(words) > 3:\n",
    "        # Check for 3+ word phrases repeating\n",
    "        for j in range(len(words) - 2):\n",
    "            phrase = \" \".join(words[j:j+3])\n",
    "            if pred.count(phrase) > 1:\n",
    "                repetition_count += 1\n",
    "                if repetition_count <= 3:\n",
    "                    print(f\"Repetition in sample {i+1}: '{phrase}'\")\n",
    "                break\n",
    "\n",
    "    # Check for truncation (ends abruptly, not with punctuation)\n",
    "    if pred and pred[-1] not in ['።', '፤', '፥', '፦', '.', '!', '?']:\n",
    "        truncation_count += 1\n",
    "\n",
    "    # Check if actually simplified (should be shorter)\n",
    "    if len(pred) >= len(orig) * 0.9:  # Less than 10% reduction\n",
    "        no_simplification += 1\n",
    "\n",
    "print(f\"\\nRepetition issues: {repetition_count}/{len(clean_test_pred_texts)} ({100*repetition_count/len(clean_test_pred_texts):.1f}%)\")\n",
    "print(f\"Truncation issues: {truncation_count}/{len(clean_test_pred_texts)} ({100*truncation_count/len(clean_test_pred_texts):.1f}%)\")\n",
    "print(f\"No simplification: {no_simplification}/{len(clean_test_pred_texts)} ({100*no_simplification/len(clean_test_pred_texts):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdAsfqtFMbFc"
   },
   "source": [
    "## 11. Qualitative Evaluation\n",
    "\n",
    "Automatic metrics are complemented with qualitative evaluation on held-out legal sentences to verify preservation of legal meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xozg5X72MbFc"
   },
   "outputs": [],
   "source": [
    "# Show sample predictions for qualitative evaluation\n",
    "print(\"=== Sample Predictions (Qualitative Evaluation) ===\\n\")\n",
    "\n",
    "num_samples = 5\n",
    "for i in range(min(num_samples, len(test_data))):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Original Legal: {test_source_sentences[i]}\")\n",
    "    print(f\"Reference Simplified: {test_target_sentences[i]}\")\n",
    "    print(f\"Model Prediction: {test_pred_texts[i]}\")\n",
    "    print(\"-\" * 80)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8As7hhyMbFc"
   },
   "source": [
    "## 12. Inference Function\n",
    "\n",
    "Function to use the fine-tuned model for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VfLbv_zMbFc"
   },
   "outputs": [],
   "source": [
    "def simplify_legal_text(legal_sentence, model, tokenizer, simplification_type=None, max_input_length=512, max_output_length=256):\n",
    "    \"\"\"Simplify legal text using the fine-tuned LLaMA model\"\"\"\n",
    "    base_instruction = \"የሕግ ቃላትን ለግለሰቦች ለመረዳት ቀላል አማርኛ ውስጥ አቅርብ: \"\n",
    "    type_map = {\n",
    "        \"vocabulary_simplification\": \"[የቃላት ማቃለል]\",\n",
    "        \"sentence_splitting\": \"[የዓረፍተ ነገር መከፋፈል]\",\n",
    "        \"deletion\": \"[መሻር]\",\n",
    "        \"unknown\": \"[አጠቃላይ]\",\n",
    "        None: \"[አጠቃላይ]\"\n",
    "    }\n",
    "    type_label = type_map.get(simplification_type, \"[አጠቃላይ]\")\n",
    "    prompted_input = base_instruction + type_label + \" \" + legal_sentence\n",
    "\n",
    "    # Tokenize input with prompt\n",
    "    inputs = tokenizer(\n",
    "        prompted_input,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    # Generate with improved parameters for decoder-only model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_output_length,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            repetition_penalty=1.3,  # Penalize repetition\n",
    "            no_repeat_ngram_size=3,  # Prevent 3-gram repetition\n",
    "            length_penalty=0.7,  # Encourage shorter outputs\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    # Decode and extract only the generated part (remove input)\n",
    "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Remove the input portion\n",
    "    if full_output.startswith(prompted_input):\n",
    "        simplified = full_output[len(prompted_input):].strip()\n",
    "    else:\n",
    "        simplified = full_output\n",
    "    return simplified\n",
    "\n",
    "# Test inference\n",
    "test_sentence = test_source_sentences[0]\n",
    "simplified = simplify_legal_text(test_sentence, model, tokenizer)\n",
    "print(f\"Original: {test_sentence}\")\n",
    "print(f\"Simplified: {simplified}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3XYSZ9-MbFc"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook fine-tuned LLaMA 3.2 400M Amharic Instruct for Amharic legal text simplification with:\n",
    "\n",
    "- **Model**: LLaMA 3.2 400M Amharic Instruct (decoder-only, instruction-tuned)\n",
    "- **LoRA**: Regularization mechanism (not freezing, end-to-end adaptation)\n",
    "  - **Capacity**: r=64, alpha=128 (increased from r=32 to utilize model capacity)\n",
    "  - **Target modules**: [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] (LLaMA attention layers)\n",
    "- **Data Split**: 1,700 train / 200 validation / 100 test (truly unseen)\n",
    "- **Training**:\n",
    "  - **Epochs**: 6 (increased from 4)\n",
    "  - **Gradient accumulation**: 8 (effective batch size: 64)\n",
    "  - **LR scheduler**: Cosine with warmup_ratio=0.1\n",
    "  - **Early stopping**: Patience 2 epochs, monitoring validation SARI\n",
    "  - **Precision**: FP16 (as requested)\n",
    "- **Label Smoothing**: 0.1\n",
    "- **Sequence Lengths**: 512 tokens input / 256 tokens output\n",
    "- **Generation**:\n",
    "  - **Repetition penalty**: 1.3\n",
    "  - **No-repeat n-gram size**: 3\n",
    "  - **Length penalty**: 0.7\n",
    "- **Metrics**: SARI (primary), BERTScore multilingual (secondary)\n",
    "- **Qualitative Evaluation**: Manual review of predictions to verify legal meaning preservation\n",
    "\n",
    "The model learns simplification behavior conditioned on simplification_type, while legal knowledge is supplied at inference time via RAG.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01ffcaf3507b4a918fd7e36b8c1472fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5bd102450035490d96557d569fb21bd2",
       "IPY_MODEL_69c0de24bf50412684809e476e0ec1ae",
       "IPY_MODEL_b4d65674747242cbaf95bc24698d2abf"
      ],
      "layout": "IPY_MODEL_783e72bb26c34e0591cf5917554768bd"
     }
    },
    "042f5350670b43a9b90887cefd647e16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14ecfcc373cc43fe9eaf9fa0de72fe64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a283683ada94ad49c898e944b4f54e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e188176142994c629c61f5f3d69ff623",
      "placeholder": "​",
      "style": "IPY_MODEL_9b4d8ef44dfb41a799f61f1b5772f567",
      "value": "Map: 100%"
     }
    },
    "1a377ab05ae144a69b98b01e2e55416f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2827a1e88af149f6b525040ceb324a4e",
      "max": 144,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d834fde5338049c095703200b550b053",
      "value": 144
     }
    },
    "1a550ea1af5c441d85f2666010425fcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26dd17af41994394b5f1ca02f41e6b31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3b7295c5c184cb0b5b3407c884574c2",
      "placeholder": "​",
      "style": "IPY_MODEL_042f5350670b43a9b90887cefd647e16",
      "value": " 782/782 [00:00&lt;00:00, 24.7kB/s]"
     }
    },
    "2827a1e88af149f6b525040ceb324a4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3127f999723941eb8c541dd9f52f797d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b121fb037a164801affc9aa0d1f729b6",
      "placeholder": "​",
      "style": "IPY_MODEL_b02ed9f84ced4ef48e913299e6d7bc84",
      "value": "config.json: 100%"
     }
    },
    "325372b44e904caa9ba0e0c9befa0ddf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94cb7b935d594f89b4e1841290ffcac8",
       "IPY_MODEL_1a377ab05ae144a69b98b01e2e55416f",
       "IPY_MODEL_fd84c3fcd3ae43bfa919002326668d42"
      ],
      "layout": "IPY_MODEL_4efca05f1d3945d281e0c013e1c01672"
     }
    },
    "33f7f049fd0e40b4bc8b1f26c11194f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a11f48e671948f288a971cd4d513e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e8e34dafcdc042739ec6301bc1557575",
       "IPY_MODEL_b66ffce02a724bc49a488658a7fe129d",
       "IPY_MODEL_525beed07ca6468e949705e36909899d"
      ],
      "layout": "IPY_MODEL_cd7eadf50b4149e4979d32f48c9f093a"
     }
    },
    "4c636329a5fc4291b787e9f44befd1ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4efca05f1d3945d281e0c013e1c01672": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "525beed07ca6468e949705e36909899d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a666042659ab482a84ec207a4528c952",
      "placeholder": "​",
      "style": "IPY_MODEL_69cfe696ffcb4c3ebe9ae37624ba7795",
      "value": " 1.65G/1.65G [00:22&lt;00:00, 177MB/s]"
     }
    },
    "53212124d8c84024b76b3d20408bbafa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bd102450035490d96557d569fb21bd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82c604c09e23437a8984b54355d236b5",
      "placeholder": "​",
      "style": "IPY_MODEL_7cd3dc1bf55740a9b85b86bfec9f6e8e",
      "value": "Map: 100%"
     }
    },
    "5cd936be671a4d3ca6532966a571f4c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "601e597d1c6440c582690dec937634ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63ea14d885db49efb2427057ea0bf41b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "642449d2bdd14f698b2fbcf81967ef8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69c0de24bf50412684809e476e0ec1ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_601e597d1c6440c582690dec937634ac",
      "max": 1700,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c238a47b77da40fa895f98bfca3d3a1e",
      "value": 1700
     }
    },
    "69cfe696ffcb4c3ebe9ae37624ba7795": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e3f0e6c36e347529b3de201b0ed71e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "783e72bb26c34e0591cf5917554768bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cd3dc1bf55740a9b85b86bfec9f6e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82c604c09e23437a8984b54355d236b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "836e8c3d29174af3b8b2d6ad14a6b103": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88616dc133134deb8b36eaddf9d29dec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3127f999723941eb8c541dd9f52f797d",
       "IPY_MODEL_a13db7f9c36d40669b338589f92467b8",
       "IPY_MODEL_26dd17af41994394b5f1ca02f41e6b31"
      ],
      "layout": "IPY_MODEL_53212124d8c84024b76b3d20408bbafa"
     }
    },
    "905de677c9a149f89853aa61f97a25d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c636329a5fc4291b787e9f44befd1ea",
      "placeholder": "​",
      "style": "IPY_MODEL_6e3f0e6c36e347529b3de201b0ed71e6",
      "value": " 200/200 [00:00&lt;00:00, 662.59 examples/s]"
     }
    },
    "94cb7b935d594f89b4e1841290ffcac8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5b4222e818846b8854bcd676dc3a8ae",
      "placeholder": "​",
      "style": "IPY_MODEL_14ecfcc373cc43fe9eaf9fa0de72fe64",
      "value": "generation_config.json: 100%"
     }
    },
    "9b4d8ef44dfb41a799f61f1b5772f567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a13db7f9c36d40669b338589f92467b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33f7f049fd0e40b4bc8b1f26c11194f7",
      "max": 782,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_efdcc3b7653a48efb20a86643b73af7c",
      "value": 782
     }
    },
    "a666042659ab482a84ec207a4528c952": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a75bc159437a44338c36361e040e20a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b02ed9f84ced4ef48e913299e6d7bc84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b121fb037a164801affc9aa0d1f729b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3cacb2c4efb41fb827f781326ac941d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a75bc159437a44338c36361e040e20a4",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd2bf9edbe8b40bb94c65bd2160b047e",
      "value": 200
     }
    },
    "b4d65674747242cbaf95bc24698d2abf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d994bb9de1c84959822739733a801e5b",
      "placeholder": "​",
      "style": "IPY_MODEL_5cd936be671a4d3ca6532966a571f4c0",
      "value": " 1700/1700 [00:02&lt;00:00, 587.03 examples/s]"
     }
    },
    "b66ffce02a724bc49a488658a7fe129d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b76542c82bff4743ae390d89fded3e2c",
      "max": 1650139320,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_642449d2bdd14f698b2fbcf81967ef8f",
      "value": 1650139320
     }
    },
    "b76542c82bff4743ae390d89fded3e2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd2bf9edbe8b40bb94c65bd2160b047e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c238a47b77da40fa895f98bfca3d3a1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3b7295c5c184cb0b5b3407c884574c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b4222e818846b8854bcd676dc3a8ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "caae7ad40ef549c8a7d452a22e4e535a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a283683ada94ad49c898e944b4f54e9",
       "IPY_MODEL_b3cacb2c4efb41fb827f781326ac941d",
       "IPY_MODEL_905de677c9a149f89853aa61f97a25d9"
      ],
      "layout": "IPY_MODEL_836e8c3d29174af3b8b2d6ad14a6b103"
     }
    },
    "cd7eadf50b4149e4979d32f48c9f093a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d834fde5338049c095703200b550b053": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d994bb9de1c84959822739733a801e5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df29dea7e70547b088225d7fdcfabdde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e188176142994c629c61f5f3d69ff623": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8e34dafcdc042739ec6301bc1557575": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a550ea1af5c441d85f2666010425fcd",
      "placeholder": "​",
      "style": "IPY_MODEL_ed8530a60c3543d78f03e2392db8949d",
      "value": "model.safetensors: 100%"
     }
    },
    "ed8530a60c3543d78f03e2392db8949d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efdcc3b7653a48efb20a86643b73af7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd84c3fcd3ae43bfa919002326668d42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63ea14d885db49efb2427057ea0bf41b",
      "placeholder": "​",
      "style": "IPY_MODEL_df29dea7e70547b088225d7fdcfabdde",
      "value": " 144/144 [00:00&lt;00:00, 2.53kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
