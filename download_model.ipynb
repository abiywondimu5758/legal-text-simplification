{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Download AfriByT5-Base Model\n",
        "\n",
        "This notebook downloads the base model (`masakhane/afri-byt5-base`) to the local `models/` folder for offline use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install -q transformers torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/blank/Documents/Foundation Models Course Projects/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading model: masakhane/afri-byt5-base\n",
            "Cache directory: /Users/blank/Documents/Foundation Models Course Projects/models\n",
            "\n",
            "This may take a few minutes...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Set cache directory to models folder\n",
        "MODEL_NAME = \"masakhane/afri-byt5-base\"\n",
        "CACHE_DIR = \"./models\"\n",
        "\n",
        "print(f\"Downloading model: {MODEL_NAME}\")\n",
        "print(f\"Cache directory: {os.path.abspath(CACHE_DIR)}\")\n",
        "print(\"\\nThis may take a few minutes...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Downloading Tokenizer ===\n",
            "‚úÖ Tokenizer downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Download tokenizer\n",
        "print(\"\\n=== Downloading Tokenizer ===\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    cache_dir=CACHE_DIR\n",
        ")\n",
        "print(\"‚úÖ Tokenizer downloaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Downloading Model ===\n",
            "This may take several minutes depending on your internet connection...\n",
            "‚úÖ Model downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Download model (this is the large file ~700MB)\n",
        "print(\"\\n=== Downloading Model ===\")\n",
        "print(\"This may take several minutes depending on your internet connection...\")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    cache_dir=CACHE_DIR\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model downloaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Verification ===\n",
            "Model files found in: ./models/models--masakhane--afri-byt5-base/snapshots/59e35ee50f6a309afe9cf8fe3a94881cd38eb9ff\n",
            "\n",
            "Files downloaded:\n",
            "  - config.json (0.00 MB)\n",
            "  - pytorch_model.bin (2223.46 MB)\n",
            "  - special_tokens_map.json (0.00 MB)\n",
            "  - tokenizer_config.json (0.00 MB)\n",
            "\n",
            "‚úÖ Required files present: True\n",
            "‚úÖ Model weights present: True\n",
            "\n",
            "üéâ Model download complete!\n"
          ]
        }
      ],
      "source": [
        "# Verify download\n",
        "print(\"\\n=== Verification ===\")\n",
        "\n",
        "model_path = os.path.join(CACHE_DIR, \"models--masakhane--afri-byt5-base\", \"snapshots\")\n",
        "if os.path.exists(model_path):\n",
        "    snapshots = os.listdir(model_path)\n",
        "    if snapshots:\n",
        "        snapshot_path = os.path.join(model_path, snapshots[0])\n",
        "        files = os.listdir(snapshot_path)\n",
        "        print(f\"Model files found in: {snapshot_path}\")\n",
        "        print(f\"\\nFiles downloaded:\")\n",
        "        for file in sorted(files):\n",
        "            file_path = os.path.join(snapshot_path, file)\n",
        "            size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "            print(f\"  - {file} ({size_mb:.2f} MB)\")\n",
        "        \n",
        "        # Check for key files\n",
        "        required_files = [\"config.json\", \"tokenizer_config.json\"]\n",
        "        has_model_weights = any(f.endswith(\".safetensors\") or f.endswith(\".bin\") for f in files)\n",
        "        \n",
        "        print(f\"\\n‚úÖ Required files present: {all(f in files for f in required_files)}\")\n",
        "        print(f\"‚úÖ Model weights present: {has_model_weights}\")\n",
        "        \n",
        "        if has_model_weights and all(f in files for f in required_files):\n",
        "            print(\"\\nüéâ Model download complete!\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è  Some files may be missing. Try re-running the download cells.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No snapshot found\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model directory not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Testing Model Load from Cache ===\n",
            "‚úÖ Model and tokenizer loaded successfully from cache!\n",
            "\n",
            "Model parameters: 581,653,248\n",
            "Tokenizer vocab size: 256\n"
          ]
        }
      ],
      "source": [
        "# Test loading the model from cache\n",
        "print(\"\\n=== Testing Model Load from Cache ===\")\n",
        "\n",
        "try:\n",
        "    # This should load from cache now\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        cache_dir=CACHE_DIR\n",
        "    )\n",
        "    \n",
        "    test_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        cache_dir=CACHE_DIR\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ Model and tokenizer loaded successfully from cache!\")\n",
        "    print(f\"\\nModel parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n",
        "    print(f\"Tokenizer vocab size: {test_tokenizer.vocab_size}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading model: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
